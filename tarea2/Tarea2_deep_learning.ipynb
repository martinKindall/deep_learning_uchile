{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea2_deep_learning.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "XUpfM3SuDS6k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tarea 2 : Clasificación y búsqueda por similitud de sketches usando redes convolucionales\n",
        "\n",
        "# CC6204 Deep Learning, Universidad de Chile <br/> Hoja de respuestas \n",
        "\n",
        "## Nombre: Martín Cornejo Saavedra\n",
        "Fecha para completar la tarea: 17 de junio de 2018"
      ]
    },
    {
      "metadata": {
        "id": "rZjPsrt_EnFd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from skimage.draw import line as drawLine\n",
        "\n",
        "import pdb\n",
        "import random\n",
        "import os\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwllwdwMuZiE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b76971f7-0da7-4d51-9582-211cf0a53062",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528392049633,
          "user_tz": 240,
          "elapsed": 841,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "Lb00DHDgGWBC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Construcción del conjunto de datos"
      ]
    },
    {
      "metadata": {
        "id": "DWHsEQiWDRr4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "raw_categories = !gsutil ls -r \"gs://quickdraw_dataset/full/simplified/*\"\n",
        "\n",
        "max_num_categories = 5\n",
        "train_samples_per_cat = 100\n",
        "test_samples_per_cat = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2SHWwUA3Jngh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Elegimos 100 categorias al azar y las descargamos"
      ]
    },
    {
      "metadata": {
        "id": "Io7kpyNfGHi0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for idx, raw_cat in enumerate(raw_categories):\n",
        "  raw_categories[idx] = raw_cat.replace(\" \", \"\\ \")   # para que bash reconozca el espacio en la descarga\n",
        "\n",
        "random_categories = []\n",
        "\n",
        "while True:\n",
        "  rand_cat = random.randint(0, len(raw_categories)-1)\n",
        "  if rand_cat not in random_categories:\n",
        "    random_categories.append(rand_cat)\n",
        "  if len(random_categories) is max_num_categories:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "22Mt8lBUEX_1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91dba8f9-8840-4252-bf8b-dd0403ed4428",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528392055852,
          "user_tz": 240,
          "elapsed": 1602,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir quick_draw_data\n",
        "os.chdir(\"/content/quick_draw_data\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘quick_draw_data’: File exists\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z97Ar-OjVPh0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "str_random_cat = []\n",
        "\n",
        "os.system(\"mkdir train\")\n",
        "os.system(\"mkdir test\")\n",
        "\n",
        "for category in random_categories:\n",
        "  aux = raw_categories[category].replace(\"gs://quickdraw_dataset/full/simplified/\", \"\")\n",
        "  aux = aux.replace(\".ndjson\", \"\")\n",
        "  str_random_cat.append(aux)\n",
        "  os.system(\"mkdir train/\" + aux)\n",
        "  os.system(\"mkdir test/\" + aux)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cynXyLqxHDtu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "d0486ca2-630c-4ab4-8f44-7eb879b531a4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528392119014,
          "user_tz": 240,
          "elapsed": 60902,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for idx, category in enumerate(random_categories):\n",
        "  os.system(\"gsutil cp \" + raw_categories[category] + \" .\")\n",
        "  print(\"La categoria \" + str(idx+1) + \" copiada es \" + raw_categories[category])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La categoria 1 copiada es gs://quickdraw_dataset/full/simplified/screwdriver.ndjson\n",
            "La categoria 2 copiada es gs://quickdraw_dataset/full/simplified/cooler.ndjson\n",
            "La categoria 3 copiada es gs://quickdraw_dataset/full/simplified/oven.ndjson\n",
            "La categoria 4 copiada es gs://quickdraw_dataset/full/simplified/kangaroo.ndjson\n",
            "La categoria 5 copiada es gs://quickdraw_dataset/full/simplified/broccoli.ndjson\n",
            "La categoria 6 copiada es gs://quickdraw_dataset/full/simplified/shorts.ndjson\n",
            "La categoria 7 copiada es gs://quickdraw_dataset/full/simplified/star.ndjson\n",
            "La categoria 8 copiada es gs://quickdraw_dataset/full/simplified/bracelet.ndjson\n",
            "La categoria 9 copiada es gs://quickdraw_dataset/full/simplified/bat.ndjson\n",
            "La categoria 10 copiada es gs://quickdraw_dataset/full/simplified/eraser.ndjson\n",
            "La categoria 11 copiada es gs://quickdraw_dataset/full/simplified/jacket.ndjson\n",
            "La categoria 12 copiada es gs://quickdraw_dataset/full/simplified/grapes.ndjson\n",
            "La categoria 13 copiada es gs://quickdraw_dataset/full/simplified/skyscraper.ndjson\n",
            "La categoria 14 copiada es gs://quickdraw_dataset/full/simplified/compass.ndjson\n",
            "La categoria 15 copiada es gs://quickdraw_dataset/full/simplified/see\\ saw.ndjson\n",
            "La categoria 16 copiada es gs://quickdraw_dataset/full/simplified/hot\\ dog.ndjson\n",
            "La categoria 17 copiada es gs://quickdraw_dataset/full/simplified/The\\ Great\\ Wall\\ of\\ China.ndjson\n",
            "La categoria 18 copiada es gs://quickdraw_dataset/full/simplified/pants.ndjson\n",
            "La categoria 19 copiada es gs://quickdraw_dataset/full/simplified/paper\\ clip.ndjson\n",
            "La categoria 20 copiada es gs://quickdraw_dataset/full/simplified/calculator.ndjson\n",
            "La categoria 21 copiada es gs://quickdraw_dataset/full/simplified/picture\\ frame.ndjson\n",
            "La categoria 22 copiada es gs://quickdraw_dataset/full/simplified/car.ndjson\n",
            "La categoria 23 copiada es gs://quickdraw_dataset/full/simplified/purse.ndjson\n",
            "La categoria 24 copiada es gs://quickdraw_dataset/full/simplified/baseball\\ bat.ndjson\n",
            "La categoria 25 copiada es gs://quickdraw_dataset/full/simplified/television.ndjson\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WpO2Vyh9JtfB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85ba3ede-d22c-48ae-9cf4-2c2bc79425de",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528392121479,
          "user_tz": 240,
          "elapsed": 2408,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "categories = !ls\n",
        "print(len(categories))\n",
        "\n",
        "for cat in str_random_cat:\n",
        "  if (cat + \".ndjson\").replace(\"\\ \", \" \") not in categories:\n",
        "    print(\"falta \" + cat)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NV6uyw8wFK30",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Se convierte la data en formato json a bitmaps de 128x128 y se guardan en formato .txt"
      ]
    },
    {
      "metadata": {
        "id": "pE7tDx5TYQyT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def parse_line(ndjson_line):\n",
        "  \"\"\"Parse an ndjson line and return ink (as np array) and classname.\"\"\"\n",
        "  sample = json.loads(ndjson_line)\n",
        "  class_name = sample[\"word\"]\n",
        "  if not class_name:\n",
        "    print (\"Empty classname\")\n",
        "    return None, None\n",
        "  inkarray = sample[\"drawing\"]\n",
        "\n",
        "  div_scale = 2\n",
        "  \n",
        "  for idx, stroke in enumerate(inkarray):\n",
        "    if len(stroke[0]) != len(stroke[1]):\n",
        "      print(\"Inconsistent number of x and y coordinates.\")\n",
        "      return None, None\n",
        "    \n",
        "    for idy, x_coord in enumerate(stroke[0]):\n",
        "      inkarray[idx][0][idy] /= div_scale\n",
        "      inkarray[idx][1][idy] /= div_scale\n",
        "  \n",
        "  return inkarray, class_name\n",
        "\n",
        "def convert_data(trainingdata_dir,\n",
        "                 observations_per_class,\n",
        "                 output_folder,\n",
        "                 offset=0):\n",
        "  file_handles = []\n",
        "  # Open all input files.\n",
        "  for filename in sorted(tf.gfile.ListDirectory(trainingdata_dir)):\n",
        "    if not filename.endswith(\".ndjson\"):\n",
        "      #print(\"Skipping\", filename)\n",
        "      continue\n",
        "    file_handles.append(\n",
        "        tf.gfile.GFile(os.path.join(trainingdata_dir, filename), \"r\"))\n",
        "    if offset:  # Fast forward all files to skip the offset.\n",
        "      count = 0\n",
        "      for _ in file_handles[-1]:\n",
        "        count += 1\n",
        "        if count == offset:\n",
        "          break\n",
        "\n",
        "    \n",
        "  reading_order = list(range(len(file_handles)))\n",
        "          \n",
        "  class_names = []  \n",
        "    \n",
        "  for idx in reading_order:\n",
        "    for pictureNum in range(observations_per_class):\n",
        "      line = file_handles[idx].readline()\n",
        "      ink = None\n",
        "      \n",
        "      while ink is None:\n",
        "        ink, class_name = parse_line(line)\n",
        "        if ink is None:\n",
        "          print (\"Couldn't parse ink from '\" + line + \"'.\")\n",
        "\n",
        "      drawing = np.zeros((128, 128), dtype=np.uint8)\n",
        "      \n",
        "      if class_name not in class_names:\n",
        "        class_names.append(class_name)      \n",
        "        os.system(\"mkdir \" + output_folder + str(idx))\n",
        "\n",
        "      for linea in ink:\n",
        "        for idy in range(len(linea[0])-1):\n",
        "          rr, cc = drawLine(linea[1][idy], linea[0][idy], linea[1][idy+1], linea[0][idy+1])\n",
        "          drawing[rr, cc] = 1\n",
        "\n",
        "      np.savetxt(output_folder + str(idx) + \"/\" + str(pictureNum) + \".txt\", drawing, fmt=\"%d\", delimiter=\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y-WnhKa1ubKQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "convert_data(\".\",\n",
        "             train_samples_per_cat,\n",
        "             \"train/\")    \n",
        "\n",
        "convert_data(\".\",\n",
        "             test_samples_per_cat,\n",
        "             \"test/\",\n",
        "             train_samples_per_cat)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Azx2iVCgzBaV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "b2970faa-dacd-40ce-c3cf-a8593ddfbcab",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528392496587,
          "user_tz": 240,
          "elapsed": 951,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_imagen = np.loadtxt(\"test/2/9.txt\")\n",
        "plt.imshow(test_imagen)\n",
        "plt.show()\n",
        "\n",
        "train_imagen = np.loadtxt(\"train/2/49.txt\")\n",
        "plt.imshow(train_imagen)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAFNCAYAAAC5YlyiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAKAAUIUAAz8H8VLwiXyQyE0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3c47f40150>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAFNCAYAAAC5YlyiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3c3a919cd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hn2SEWbuNrHl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "5ef22ccf-90f9-4edf-f67c-6e898e38d81b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528392498663,
          "user_tz": 240,
          "elapsed": 1866,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls test/4"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.txt\t14.txt\t19.txt\t23.txt\t28.txt\t32.txt\t37.txt\t41.txt\t46.txt\t5.txt\r\n",
            "10.txt\t15.txt\t1.txt\t24.txt\t29.txt\t33.txt\t38.txt\t42.txt\t47.txt\t6.txt\r\n",
            "11.txt\t16.txt\t20.txt\t25.txt\t2.txt\t34.txt\t39.txt\t43.txt\t48.txt\t7.txt\r\n",
            "12.txt\t17.txt\t21.txt\t26.txt\t30.txt\t35.txt\t3.txt\t44.txt\t49.txt\t8.txt\r\n",
            "13.txt\t18.txt\t22.txt\t27.txt\t31.txt\t36.txt\t40.txt\t45.txt\t4.txt\t9.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gYUHVu3iFXTM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Construcción y entrenamiento de la skNet"
      ]
    },
    {
      "metadata": {
        "id": "qeY5sZVQRGRL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Construcción del grafo"
      ]
    },
    {
      "metadata": {
        "id": "fSiarO2jzL3g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def deepnn(x, training=False):\n",
        "  with tf.name_scope('reshape'):\n",
        "    x_image = tf.reshape(x, [-1, 128, 128, 1])       \n",
        "\n",
        "  conv1_1 = tf.layers.conv2d(\n",
        "    inputs=x_image,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv1_1_n = tf.contrib.layers.batch_norm(conv1_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv1_2 = tf.layers.conv2d(\n",
        "    inputs=conv1_1_n,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv1_2_n = tf.contrib.layers.batch_norm(conv1_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "\n",
        "  pool1 = tf.layers.max_pooling2d(inputs=conv1_2_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  conv2_1 = tf.layers.conv2d(\n",
        "    inputs=pool1,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv2_1_n = tf.contrib.layers.batch_norm(conv2_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv2_2 = tf.layers.conv2d(\n",
        "    inputs=conv2_1_n,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv2_2_n = tf.contrib.layers.batch_norm(conv2_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "\n",
        "  pool2 = tf.layers.max_pooling2d(inputs=conv2_2_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  conv3_1 = tf.layers.conv2d(\n",
        "    inputs=pool2,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv3_1_n = tf.contrib.layers.batch_norm(conv3_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv3_2 = tf.layers.conv2d(\n",
        "    inputs=conv3_1_n,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv3_2_n = tf.contrib.layers.batch_norm(conv3_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "\n",
        "  pool3 = tf.layers.max_pooling2d(inputs=conv3_2_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  conv4_1 = tf.layers.conv2d(\n",
        "    inputs=pool3,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv4_1_n = tf.contrib.layers.batch_norm(conv4_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv4_2 = tf.layers.conv2d(\n",
        "    inputs=conv4_1_n,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv4_2_n = tf.contrib.layers.batch_norm(conv4_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "\n",
        "  pool4 = tf.layers.max_pooling2d(inputs=conv4_2_n, pool_size=[3, 3], strides=2)\n",
        "\n",
        "  # Dense layer\n",
        "  \n",
        "  pool2_flat = tf.reshape(pool4, [-1, 7*7*256])\n",
        "  dense_l = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
        "  \n",
        "  # Logits Layer\n",
        "  \n",
        "  logits = tf.layers.dense(inputs=dense_l, units=max_num_categories)\n",
        "  \n",
        "  return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JyMSjf1nOQli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Se crea una clase para extraer datos de entrenamiento"
      ]
    },
    {
      "metadata": {
        "id": "q4dPgoCvOP9j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class QuickDataset():\n",
        "  def __init__(self, data_path, samples_per_cat):    \n",
        "    self.x = []\n",
        "    self.y = []\n",
        "    \n",
        "    for idx in range(max_num_categories):\n",
        "      folder = \"/\" + str(idx)\n",
        "  \n",
        "      for idy in range(samples_per_cat):\n",
        "           \n",
        "        train_input = np.loadtxt(data_path + folder + \"/\" + str(idy) + \".txt\")\n",
        "        self.x.append(np.resize(train_input, (1, 16384))[0])\n",
        "        #self.y.append(np.eye(max_num_categories)[np.array(idx)])\n",
        "        self.y.append(idx)\n",
        "  \n",
        "  def paquetes(self, B):\n",
        "       \n",
        "    n_iters = int(len(self.x)/B)\n",
        "    arr_paquetes = []\n",
        "   \n",
        "    for index in range(n_iters):\n",
        "      arr_paquetes.append(self.elige_batch(self.x,self.y,B))\n",
        "              \n",
        "    self.arr_paquetes = arr_paquetes\n",
        "      \n",
        "    return self.arr_paquetes\n",
        "  \n",
        "  def elige_batch(self, X, Y, b):\n",
        "    N = len(self.x)\n",
        "    x_lista = []\n",
        "    y_lista = []\n",
        "  \n",
        "    for _ in range(b):\n",
        "      i = np.random.randint(N)\n",
        "      x_lista.append(X[i:i+1])\n",
        "      y_lista.append(Y[i:i+1])\n",
        "  \n",
        "    x = np.concatenate(x_lista, axis=0)\n",
        "    y = np.concatenate(y_lista, axis=0)\n",
        "  \n",
        "    return x, y\n",
        "  \n",
        "train_dataset = QuickDataset(\"train\", train_samples_per_cat)\n",
        "test_dataset = QuickDataset(\"test\", test_samples_per_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vCs0P712RNJJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento de skNet"
      ]
    },
    {
      "metadata": {
        "id": "nJlFunVeHA3g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "65f68245-1744-4cb9-932b-6afc8fc6487c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528395186056,
          "user_tz": 240,
          "elapsed": 6584,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float16, shape=(None, 128*128))\n",
        "y_ = tf.placeholder(tf.int64, shape=(None))\n",
        "y_conv = deepnn(x, True)\n",
        "    \n",
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_,\n",
        "                                                          logits=y_conv)\n",
        "cross_entropy = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "# hiperparámetros de entrenamiento\n",
        "batch_size = 10\n",
        "n_epochs = 1\n",
        "learning_rate= 0.001\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train_step = train_step.minimize(cross_entropy)\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv, 1), y_)\n",
        "correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
        "accuracy = tf.reduce_mean(correct_prediction)\n",
        "\n",
        "loss_array = []\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "test_acc = []   \n",
        "cnf_matrix = []\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init = tf.global_variables_initializer()\n",
        "  init.run()    \n",
        "  for idz in range(n_epochs):\n",
        "    batches = train_dataset.paquetes(batch_size)\n",
        "    \n",
        "    for idx, batch in enumerate(batches): \n",
        "      #pdb.set_trace()\n",
        "      if idx % 5 == 0:\n",
        "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1]})\n",
        "        print('step %d, training set accuracy %g' % (idx, train_accuracy))      \n",
        "      \n",
        "      sess.run(train_step, feed_dict={x: batch[0], y_: batch[1]})\n",
        "    \n",
        "  test_batches = test_dataset.paquetes(test_samples_per_cat)\n",
        "  test_acc = []\n",
        "    \n",
        "  for idy, test_batch in enumerate(test_batches): \n",
        "    test_acc.append(accuracy.eval(feed_dict={x: test_batch[0], y_: test_batch[1]}))  \n",
        "    \n",
        "  print('test set accuracy ' + str(sum(test_acc)/len(test_acc)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training set accuracy 0.2\n",
            "step 5, training set accuracy 0.3\n",
            "step 10, training set accuracy 0.3\n",
            "step 15, training set accuracy 0.4\n",
            "step 20, training set accuracy 0.6\n",
            "step 25, training set accuracy 0.4\n",
            "step 30, training set accuracy 0.2\n",
            "step 35, training set accuracy 0.7\n",
            "step 40, training set accuracy 0.7\n",
            "step 45, training set accuracy 0.7\n",
            "test set accuracy 0.5200000047683716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "noiUU9T9Wgkm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Construcción y entrenamiento de la skResNet"
      ]
    },
    {
      "metadata": {
        "id": "z9aoZp_rWlzg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Construcción del grafo"
      ]
    },
    {
      "metadata": {
        "id": "ST115cKqWiRw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def skResNet(x, training=False):\n",
        "  with tf.name_scope('reshape'):\n",
        "    x_image = tf.reshape(x, [-1, 128, 128, 1])       \n",
        "\n",
        "  conv1_1 = tf.layers.conv2d(\n",
        "    inputs=x_image,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv1_1_n = tf.contrib.layers.batch_norm(conv1_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv1_2 = tf.layers.conv2d(\n",
        "    inputs=conv1_1_n,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv1_2_n = tf.contrib.layers.batch_norm(conv1_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "\n",
        "  pool1 = tf.layers.max_pooling2d(inputs=conv1_2_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  conv2_1 = tf.layers.conv2d(\n",
        "    inputs=pool1,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv2_1_n = tf.contrib.layers.batch_norm(conv2_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv2_2 = tf.layers.conv2d(\n",
        "    inputs=conv2_1_n,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv2_2_n = tf.contrib.layers.batch_norm(conv2_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  residual_1 = conv2_2_n + pool1\n",
        "  \n",
        "  conv3_1 = tf.layers.conv2d(\n",
        "    inputs=residual_1,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv3_1_n = tf.contrib.layers.batch_norm(conv3_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv3_2 = tf.layers.conv2d(\n",
        "    inputs=conv3_1_n,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv3_2_n = tf.contrib.layers.batch_norm(conv3_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  residual_2 = conv3_2_n + residual_1\n",
        "  \n",
        "  conv4_1 = tf.layers.conv2d(\n",
        "    inputs=residual_2,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv4_1_n = tf.contrib.layers.batch_norm(conv4_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  pool2 = tf.layers.max_pooling2d(inputs=conv4_1_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  conv5_1 = tf.layers.conv2d(\n",
        "    inputs=pool2,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv5_1_n = tf.contrib.layers.batch_norm(conv5_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv5_2 = tf.layers.conv2d(\n",
        "    inputs=conv5_1_n,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv5_2_n = tf.contrib.layers.batch_norm(conv5_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  residual_3 = conv5_2_n + pool2\n",
        "  \n",
        "  conv6_1 = tf.layers.conv2d(\n",
        "    inputs=residual_3,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv6_1_n = tf.contrib.layers.batch_norm(conv6_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv6_2 = tf.layers.conv2d(\n",
        "    inputs=conv6_1_n,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv6_2_n = tf.contrib.layers.batch_norm(conv6_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  residual_4 = conv6_2_n + residual_3\n",
        "  \n",
        "  conv7_1 = tf.layers.conv2d(\n",
        "    inputs=residual_4,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv7_1_n = tf.contrib.layers.batch_norm(conv7_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  pool3 = tf.layers.max_pooling2d(inputs=conv7_1_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  conv8_1 = tf.layers.conv2d(\n",
        "    inputs=pool3,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv8_1_n = tf.contrib.layers.batch_norm(conv8_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv8_2 = tf.layers.conv2d(\n",
        "    inputs=conv8_1_n,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv8_2_n = tf.contrib.layers.batch_norm(conv8_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  residual_5 = conv8_2_n + pool3\n",
        "  \n",
        "  conv9_1 = tf.layers.conv2d(\n",
        "    inputs=residual_5,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv9_1_n = tf.contrib.layers.batch_norm(conv9_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  conv9_2 = tf.layers.conv2d(\n",
        "    inputs=conv9_1_n,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv9_2_n = tf.contrib.layers.batch_norm(conv9_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  residual_6 = conv9_2_n + residual_5\n",
        "  \n",
        "  conv10_1 = tf.layers.conv2d(\n",
        "    inputs=residual_6,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu)\n",
        "  \n",
        "  conv10_1_n = tf.contrib.layers.batch_norm(conv10_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training)\n",
        "  \n",
        "  pool4 = tf.layers.max_pooling2d(inputs=conv10_1_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  # Dense layer\n",
        "  \n",
        "  pool2_flat = tf.reshape(pool4, [-1, 7*7*256])\n",
        "  dense_l = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
        "  \n",
        "  # Logits Layer\n",
        "  \n",
        "  logits = tf.layers.dense(inputs=dense_l, units=max_num_categories)\n",
        "  \n",
        "  return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q89XfUjXcO1S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento de skResNet"
      ]
    },
    {
      "metadata": {
        "id": "qn00RoAVcL79",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "32edc7ff-e00a-4891-ddfb-299c0e0a092b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528396460635,
          "user_tz": 240,
          "elapsed": 38183,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float16, shape=(None, 128*128))\n",
        "y_ = tf.placeholder(tf.int64, shape=(None))\n",
        "y_conv = skResNet(x, True)\n",
        "    \n",
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_,\n",
        "                                                          logits=y_conv)\n",
        "cross_entropy = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "# hiperparámetros de entrenamiento\n",
        "batch_size = 10\n",
        "n_epochs = 5\n",
        "learning_rate= 0.001\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train_step = train_step.minimize(cross_entropy)\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv, 1), y_)\n",
        "correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
        "accuracy = tf.reduce_mean(correct_prediction)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init = tf.global_variables_initializer()\n",
        "  init.run()    \n",
        "  for idz in range(n_epochs):\n",
        "    batches = train_dataset.paquetes(batch_size)\n",
        "    \n",
        "    for idx, batch in enumerate(batches): \n",
        "      #pdb.set_trace()\n",
        "      if idx % 5 == 0:\n",
        "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1]})\n",
        "        print('step %d, training set accuracy %g' % (idx, train_accuracy))      \n",
        "      \n",
        "      sess.run(train_step, feed_dict={x: batch[0], y_: batch[1]})\n",
        "    \n",
        "  test_batches = test_dataset.paquetes(test_samples_per_cat)\n",
        "  test_acc = []\n",
        "    \n",
        "  for idy, test_batch in enumerate(test_batches): \n",
        "    test_acc.append(accuracy.eval(feed_dict={x: test_batch[0], y_: test_batch[1]}))  \n",
        "    \n",
        "  print('test set accuracy ' + str(sum(test_acc)/len(test_acc)))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training set accuracy 0\n",
            "step 5, training set accuracy 0.2\n",
            "step 10, training set accuracy 0.5\n",
            "step 15, training set accuracy 0.5\n",
            "step 20, training set accuracy 0.4\n",
            "step 25, training set accuracy 0.5\n",
            "step 30, training set accuracy 0.5\n",
            "step 35, training set accuracy 0.8\n",
            "step 40, training set accuracy 0.4\n",
            "step 45, training set accuracy 0.5\n",
            "step 0, training set accuracy 0.7\n",
            "step 5, training set accuracy 1\n",
            "step 10, training set accuracy 0.8\n",
            "step 15, training set accuracy 0.7\n",
            "step 20, training set accuracy 0.7\n",
            "step 25, training set accuracy 1\n",
            "step 30, training set accuracy 0.6\n",
            "step 35, training set accuracy 0.8\n",
            "step 40, training set accuracy 0.8\n",
            "step 45, training set accuracy 0.6\n",
            "step 0, training set accuracy 1\n",
            "step 5, training set accuracy 0.6\n",
            "step 10, training set accuracy 0.8\n",
            "step 15, training set accuracy 0.9\n",
            "step 20, training set accuracy 0.9\n",
            "step 25, training set accuracy 0.8\n",
            "step 30, training set accuracy 0.9\n",
            "step 35, training set accuracy 1\n",
            "step 40, training set accuracy 0.8\n",
            "step 45, training set accuracy 0.8\n",
            "step 0, training set accuracy 1\n",
            "step 5, training set accuracy 0.8\n",
            "step 10, training set accuracy 0.9\n",
            "step 15, training set accuracy 0.9\n",
            "step 20, training set accuracy 0.8\n",
            "step 25, training set accuracy 0.9\n",
            "step 30, training set accuracy 1\n",
            "step 35, training set accuracy 0.9\n",
            "step 40, training set accuracy 1\n",
            "step 45, training set accuracy 0.9\n",
            "step 0, training set accuracy 1\n",
            "step 5, training set accuracy 0.9\n",
            "step 10, training set accuracy 0.8\n",
            "step 15, training set accuracy 0.9\n",
            "step 20, training set accuracy 0.9\n",
            "step 25, training set accuracy 0.9\n",
            "step 30, training set accuracy 1\n",
            "step 35, training set accuracy 1\n",
            "step 40, training set accuracy 1\n",
            "step 45, training set accuracy 1\n",
            "test set accuracy 0.7\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}