{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea2_deep_learning.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "XUpfM3SuDS6k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tarea 2 : Clasificación y búsqueda por similitud de sketches usando redes convolucionales\n",
        "\n",
        "# CC6204 Deep Learning, Universidad de Chile <br/> Hoja de respuestas \n",
        "\n",
        "## Nombre: Martín Cornejo Saavedra\n",
        "Fecha para completar la tarea: 17 de junio de 2018"
      ]
    },
    {
      "metadata": {
        "id": "hrwjSdk5A53q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SkSB_RByBEOx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "df0b801c-3600-430d-a377-32f68f012680",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532569905241,
          "user_tz": 240,
          "elapsed": 18490,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive ## you will have install for every colab session\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "\n",
        "\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "# Work around misordering of STREAM and STDIN in Jupyter.\n",
        "# https://github.com/jupyter/notebook/issues/3159\n",
        "prompt = !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass(prompt[0] + '\\n\\nEnter verification code: ')\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "\n",
            "Enter verification code: ··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X0ZnhWN63WV4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHhRuFxZBUmL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "print 'Files in Drive:'\n",
        "!ls drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZjPsrt_EnFd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from skimage.draw import line as drawLine\n",
        "\n",
        "import pdb\n",
        "import random\n",
        "import os\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwllwdwMuZiE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cce77699-bbea-472b-b060-fdffa9d7b3be",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532569927102,
          "user_tz": 240,
          "elapsed": 1853,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Lb00DHDgGWBC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Construcción del conjunto de datos"
      ]
    },
    {
      "metadata": {
        "id": "DWHsEQiWDRr4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#raw_categories = !gsutil ls -r \"gs://quickdraw_dataset/full/simplified/*\"\n",
        "\n",
        "max_num_categories = 100\n",
        "train_samples_per_cat = 1000\n",
        "test_samples_per_cat = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qpowWwTV8Z8M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Importar dataset previamente construido"
      ]
    },
    {
      "metadata": {
        "id": "6x-2A0Lb8Zb4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!cp drive/data_quickdraw/train.tar.gz train.tar.gz \n",
        "!cp drive/data_quickdraw/test.tar.gz test.tar.gz "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pN-1qhcpADi8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29b3edb7-7b36-4c0b-ffe0-db24c88eed9b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532570005503,
          "user_tz": 240,
          "elapsed": 27150,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!tar xzf train.tar.gz\n",
        "!tar xzf test.tar.gz\n",
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  drive\ttest  test.tar.gz  train  train.tar.gz\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RXpprCsr760t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Importar modelo previamente entrenado"
      ]
    },
    {
      "metadata": {
        "id": "V2AHPdwi7-JI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "9a423d26-e021-4d08-cf9e-622841ced2f8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532555373282,
          "user_tz": 240,
          "elapsed": 25007,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf training/\n",
        "!rm -rf training_sknet/\n",
        "\n",
        "!cp drive/data_quickdraw/training.zip training.zip\n",
        "!unzip training.zip -d training/\n",
        "\n",
        "!cp drive/data_quickdraw/training_sknet.zip training_sknet.zip\n",
        "!unzip training_sknet.zip -d training_sknet/\n",
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  training.zip\r\n",
            "   creating: training/training/\r\n",
            "  inflating: training/training/checkpoint  \r\n",
            "  inflating: training/training/snap-skresnet.ckpt.index  \n",
            "  inflating: training/training/snap-data  \n",
            "  inflating: training/training/snap-skresnet.ckpt.data-00000-of-00001  \n",
            "  inflating: training/training/snap-skresnet.ckpt.meta  \n",
            "Archive:  training_sknet.zip\n",
            "   creating: training_sknet/training/\n",
            "  inflating: training_sknet/training/checkpoint  \n",
            "  inflating: training_sknet/training/snap-sknet.ckpt.data-00000-of-00001  \n",
            "  inflating: training_sknet/training/snap-sknet.ckpt.index  \n",
            "  inflating: training_sknet/training/snap-sknet.ckpt.meta  \n",
            "datalab  test\t      train\ttraining_sknet\t    training.zip\n",
            "drive\t test.tar.gz  training\ttraining_sknet.zip  train.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2SHWwUA3Jngh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Elegimos 100 categorias al azar y las descargamos (realizar sólo una vez)"
      ]
    },
    {
      "metadata": {
        "id": "Io7kpyNfGHi0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for idx, raw_cat in enumerate(raw_categories):\n",
        "  raw_categories[idx] = raw_cat.replace(\" \", \"\\ \")   # para que bash reconozca el espacio en la descarga\n",
        "\n",
        "random_categories = []\n",
        "\n",
        "while True:\n",
        "  rand_cat = random.randint(0, len(raw_categories)-1)\n",
        "  if rand_cat not in random_categories:\n",
        "    random_categories.append(rand_cat)\n",
        "  if len(random_categories) is max_num_categories:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "22Mt8lBUEX_1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3d1becad-39cc-4d69-e91d-68639b97b709",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528832412754,
          "user_tz": 240,
          "elapsed": 2862,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#!mkdir quick_draw_data\n",
        "#os.chdir(\"/content/quick_draw_data\")\n",
        "!mkdir training"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘training’: File exists\n",
            "datalab  training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z97Ar-OjVPh0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "str_random_cat = []\n",
        "\n",
        "os.system(\"mkdir train\")\n",
        "os.system(\"mkdir test\")\n",
        "\n",
        "for category in random_categories:\n",
        "  aux = raw_categories[category].replace(\"gs://quickdraw_dataset/full/simplified/\", \"\")\n",
        "  aux = aux.replace(\".ndjson\", \"\")\n",
        "  str_random_cat.append(aux)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cynXyLqxHDtu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "ddb86132-c19f-4707-8403-f1469ccb5906",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528644257987,
          "user_tz": 240,
          "elapsed": 12736,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for idx, category in enumerate(random_categories):\n",
        "  os.system(\"gsutil cp \" + raw_categories[category] + \" .\")\n",
        "  print(\"La categoria \" + str(idx+1) + \" copiada es \" + raw_categories[category])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La categoria 1 copiada es gs://quickdraw_dataset/full/simplified/donut.ndjson\n",
            "La categoria 2 copiada es gs://quickdraw_dataset/full/simplified/fan.ndjson\n",
            "La categoria 3 copiada es gs://quickdraw_dataset/full/simplified/blackberry.ndjson\n",
            "La categoria 4 copiada es gs://quickdraw_dataset/full/simplified/helmet.ndjson\n",
            "La categoria 5 copiada es gs://quickdraw_dataset/full/simplified/airplane.ndjson\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WpO2Vyh9JtfB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5715fdf-43ee-4c7f-9b4f-7931f8b6a07f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528644261708,
          "user_tz": 240,
          "elapsed": 1658,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "categories = !ls\n",
        "print(len(categories))\n",
        "\n",
        "for cat in str_random_cat:\n",
        "  if (cat + \".ndjson\").replace(\"\\ \", \" \") not in categories:\n",
        "    print(\"falta \" + cat)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NV6uyw8wFK30",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Se convierte la data en formato json a bitmaps de 128x128 y se guardan en formato .txt"
      ]
    },
    {
      "metadata": {
        "id": "pE7tDx5TYQyT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def parse_line(ndjson_line):\n",
        "  \"\"\"Parse an ndjson line and return ink (as np array) and classname.\"\"\"\n",
        "  sample = json.loads(ndjson_line)\n",
        "  class_name = sample[\"word\"]\n",
        "  if not class_name:\n",
        "    print (\"Empty classname\")\n",
        "    return None, None\n",
        "  inkarray = sample[\"drawing\"]\n",
        "\n",
        "  div_scale = 2\n",
        "  \n",
        "  for idx, stroke in enumerate(inkarray):\n",
        "    if len(stroke[0]) != len(stroke[1]):\n",
        "      print(\"Inconsistent number of x and y coordinates.\")\n",
        "      return None, None\n",
        "    \n",
        "    for idy, x_coord in enumerate(stroke[0]):\n",
        "      inkarray[idx][0][idy] /= div_scale\n",
        "      inkarray[idx][1][idy] /= div_scale\n",
        "  \n",
        "  return inkarray, class_name\n",
        "\n",
        "def convert_data(trainingdata_dir,\n",
        "                 observations_per_class,\n",
        "                 output_folder,\n",
        "                 offset=0):\n",
        "  \n",
        "  file_handles = []\n",
        "  # Open all input files.\n",
        "  for filename in sorted(tf.gfile.ListDirectory(trainingdata_dir)):\n",
        "    if not filename.endswith(\".ndjson\"):\n",
        "      #print(\"Skipping\", filename)\n",
        "      continue\n",
        "    file_handles.append(\n",
        "        tf.gfile.GFile(os.path.join(trainingdata_dir, filename), \"r\"))\n",
        "    if offset:  # Fast forward all files to skip the offset.\n",
        "      count = 0\n",
        "      for _ in file_handles[-1]:\n",
        "        count += 1\n",
        "        if count == offset:\n",
        "          break\n",
        "\n",
        "    \n",
        "  reading_order = list(range(len(file_handles)))\n",
        "          \n",
        "  class_names = []  \n",
        "  class_names_pairs = []\n",
        "    \n",
        "  for idx in reading_order:\n",
        "    for pictureNum in range(observations_per_class):\n",
        "      line = file_handles[idx].readline()\n",
        "      ink = None\n",
        "      \n",
        "      while ink is None:\n",
        "        ink, class_name = parse_line(line)\n",
        "        if ink is None:\n",
        "          print (\"Couldn't parse ink from '\" + line + \"'.\")\n",
        "\n",
        "      drawing = np.zeros((128, 128), dtype=np.uint8)\n",
        "      \n",
        "      if class_name not in class_names:\n",
        "        class_names.append(class_name)  \n",
        "        class_names_pairs.append((idx, class_name))      \n",
        "        os.system(\"mkdir \" + output_folder + str(idx))\n",
        "        print(str(idx) + \";\" + class_name)\n",
        "\n",
        "      for linea in ink:\n",
        "        for idy in range(len(linea[0])-1):\n",
        "          rr, cc = drawLine(linea[1][idy], linea[0][idy], linea[1][idy+1], linea[0][idy+1])\n",
        "          drawing[rr, cc] = 1\n",
        "\n",
        "      np.savetxt(output_folder + str(idx) + \"/\" + str(pictureNum) + \".txt\", drawing, fmt=\"%d\", delimiter=\" \")\n",
        "\n",
        "  return class_names_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y-WnhKa1ubKQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class_names_train = convert_data(\".\",\n",
        "             train_samples_per_cat,\n",
        "             \"train/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pOQBSBqN9Qzx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class_names_test = convert_data(\".\",\n",
        "             test_samples_per_cat,\n",
        "             \"test/\",\n",
        "             train_samples_per_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Azx2iVCgzBaV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "outputId": "0464072f-42f6-4651-f118-d2458ebf8a01",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532570450428,
          "user_tz": 240,
          "elapsed": 980,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_imagen = np.loadtxt(\"test/12/9.txt\")\n",
        "plt.imshow(test_imagen)\n",
        "plt.show()\n",
        "\n",
        "train_imagen = np.loadtxt(\"train/12/99.txt\")\n",
        "plt.imshow(train_imagen)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAFNCAYAAAC5YlyiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRAHAwH8AyygJ10UEKv0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2043c89e10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAFNCAYAAAC5YlyiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2043d870d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XFkxamZo9GZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Descargar Dataset"
      ]
    },
    {
      "metadata": {
        "id": "hn2SEWbuNrHl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!tar czf train.tar.gz train/\n",
        "!tar czf test.tar.gz test/\n",
        "files.download('train.tar.gz') \n",
        "files.download('test.tar.gz') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JyMSjf1nOQli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Se crea una clase para extraer datos de entrenamiento"
      ]
    },
    {
      "metadata": {
        "id": "q4dPgoCvOP9j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class QuickDataset():\n",
        "  def __init__(self, data_path, samples_per_cat):            \n",
        "    self.samples = samples_per_cat\n",
        "    self.data_path = data_path + \"/\"    \n",
        "  \n",
        "  def get_batch(self, batch_size):\n",
        "    x_lista = []\n",
        "    y_lista = []    \n",
        "    \n",
        "    for _ in range(batch_size):\n",
        "      cat = np.random.randint(max_num_categories)\n",
        "      sample = np.random.randint(self.samples)\n",
        "      \n",
        "      train_input = np.loadtxt(self.data_path + str(cat) + \"/\" + str(sample) + \".txt\")\n",
        "      x_lista.append(np.resize(train_input, (1, 16384))[0])\n",
        "      y_lista.append(cat)\n",
        "  \n",
        "    return x_lista, y_lista\n",
        "    \n",
        "train_dataset = QuickDataset(\"train\", train_samples_per_cat)\n",
        "test_dataset = QuickDataset(\"test\", test_samples_per_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mXt86OpEaGCI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Función de entrenamiento"
      ]
    },
    {
      "metadata": {
        "id": "kuih0U8haI4K",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train_net(dnn_graph, batch_size, n_epochs, learning_rate, snapshot_path, loadPrev = False, layer_scopes=[], respaldar=False, earlyExit=False):\n",
        "  \n",
        "  x = tf.placeholder(tf.float16, shape=(None, 128*128))\n",
        "  y_ = tf.placeholder(tf.int64, shape=(None))\n",
        "  y_conv = dnn_graph(x, True)\n",
        "  \n",
        "  with tf.name_scope('accurracy'):\n",
        "  \n",
        "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_,\n",
        "                                                              logits=y_conv)\n",
        "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "    train_step = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    train_step = train_step.minimize(cross_entropy)\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), y_)\n",
        "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
        "    accuracy = tf.reduce_mean(correct_prediction)\n",
        "\n",
        "  loss_array = []\n",
        "  train_acc = []\n",
        "  test_acc = []\n",
        "  \n",
        "  batches_per_epoch = max_num_categories * train_samples_per_cat / batch_size\n",
        "  \n",
        "  test_batches_per_epoch = max_num_categories * test_samples_per_cat / batch_size\n",
        "  \n",
        "  with tf.Session() as sess:              \n",
        "    \n",
        "    if loadPrev:\n",
        "      reuse_vars = []\n",
        "      \n",
        "      for cusScope in layer_scopes:\n",
        "        reuse_vars += tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                     scope=cusScope)      \n",
        "      #pdb.set_trace()\n",
        "      reuse_vars_dict = dict([(var.op.name, var) for var in reuse_vars])\n",
        "      saver = tf.train.Saver(reuse_vars_dict)\n",
        "      saver.restore(sess, snapshot_path)\n",
        "    else:     \n",
        "      init = tf.global_variables_initializer()\n",
        "      saver = tf.train.Saver()\n",
        "      init.run()   \n",
        "    \n",
        "    for idz in range(n_epochs * batches_per_epoch + 1):\n",
        "      batch = train_dataset.get_batch(batch_size)\n",
        "        \n",
        "      if idz % 20 == 0:\n",
        "        train_accuracy = accuracy.eval(session=sess, feed_dict={x: batch[0], y_: batch[1]})\n",
        "        print('step %d, training set accuracy %g' % (idz, train_accuracy))\n",
        "        loss_array.append(cross_entropy.eval(feed_dict={x: batch[0], y_: batch[1]}))\n",
        "        #train_acc.append(train_accuracy)\n",
        "\n",
        "      if idz % 20 == 0 and idz > 0:        \n",
        "        test_acc_aux = []\n",
        "        for idy in range(test_batches_per_epoch): \n",
        "          test_batch = test_dataset.get_batch(batch_size)\n",
        "          test_acc_aux.append(accuracy.eval(feed_dict={x: test_batch[0], y_: test_batch[1]}))  \n",
        "\n",
        "        test_acc_mean = sum(test_acc_aux)/len(test_acc_aux)  \n",
        "        print('test set accuracy ' + str(test_acc_mean))\n",
        "        \n",
        "        if (respaldar):\n",
        "          saved_path = saver.save(sess, snapshot_path)\n",
        "          !zip -r training.zip training/\n",
        "          !cp training.zip drive/data_quickdraw/training.zip\n",
        "        \n",
        "        if (earlyExit):\n",
        "          return loss_array, train_acc, test_acc\n",
        "\n",
        "      sess.run(train_step, feed_dict={x: batch[0], y_: batch[1]})\n",
        "  \n",
        "    if (respaldar):\n",
        "      saved_path = saver.save(sess, snapshot_path)\n",
        "      !zip -r training.zip training/\n",
        "      !cp training.zip drive/data_quickdraw/training.zip\n",
        "    \n",
        "  return loss_array, train_acc, test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gYUHVu3iFXTM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Construcción y entrenamiento de la skNet"
      ]
    },
    {
      "metadata": {
        "id": "qeY5sZVQRGRL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Construcción del grafo"
      ]
    },
    {
      "metadata": {
        "id": "fSiarO2jzL3g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def skNet(x, training=False, features=False):\n",
        "  with tf.name_scope('skNet'):\n",
        "    x_image = tf.reshape(x, [-1, 128, 128, 1])       \n",
        " \n",
        "    conv1_1 = tf.layers.conv2d(\n",
        "      inputs=x_image,\n",
        "      filters=64,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu,\n",
        "      name=\"conv1\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "\n",
        "    conv1_1_n = tf.contrib.layers.batch_norm(conv1_1,\n",
        "                                      center=True,\n",
        "                                      scale=True, \n",
        "                                      is_training=training,\n",
        "                                            scope=\"convb1\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    conv1_2 = tf.layers.conv2d(\n",
        "      inputs=conv1_1_n,\n",
        "      filters=64,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu,\n",
        "      name=\"conv2\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "\n",
        "    conv1_2_n = tf.contrib.layers.batch_norm(conv1_2,\n",
        "                                        center=True,\n",
        "                                        scale=True, \n",
        "                                        is_training=training,\n",
        "                                            scope=\"convb2\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1_2_n, pool_size=[3, 3], strides=2)\n",
        "\n",
        "    conv2_1 = tf.layers.conv2d(\n",
        "      inputs=pool1,\n",
        "      filters=128,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu,\n",
        "      name=\"conv3\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "\n",
        "    conv2_1_n = tf.contrib.layers.batch_norm(conv2_1,\n",
        "                                        center=True,\n",
        "                                        scale=True, \n",
        "                                        is_training=training,\n",
        "                                            scope=\"convb3\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    conv2_2 = tf.layers.conv2d(\n",
        "        inputs=conv2_1_n,\n",
        "        filters=128,\n",
        "        kernel_size=[3, 3],\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu,\n",
        "        name=\"conv4\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "\n",
        "    conv2_2_n = tf.contrib.layers.batch_norm(conv2_2,\n",
        "                                        center=True,\n",
        "                                        scale=True, \n",
        "                                        is_training=training,\n",
        "                                            scope=\"convb4\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2_2_n, pool_size=[3, 3], strides=2)\n",
        "\n",
        "    conv3_1 = tf.layers.conv2d(\n",
        "        inputs=pool2,\n",
        "        filters=128,\n",
        "        kernel_size=[3, 3],\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu,\n",
        "        name=\"conv5\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "\n",
        "    conv3_1_n = tf.contrib.layers.batch_norm(conv3_1,\n",
        "                                        center=True,\n",
        "                                        scale=True, \n",
        "                                        is_training=training,\n",
        "                                            scope=\"convb5\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    conv3_2 = tf.layers.conv2d(\n",
        "        inputs=conv3_1_n,\n",
        "        filters=128,\n",
        "        kernel_size=[3, 3],\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu,\n",
        "        name=\"conv6\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "\n",
        "    conv3_2_n = tf.contrib.layers.batch_norm(conv3_2,\n",
        "                                        center=True,\n",
        "                                        scale=True, \n",
        "                                        is_training=training,\n",
        "                                            scope=\"convb6\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    pool3 = tf.layers.max_pooling2d(inputs=conv3_2_n, pool_size=[3, 3], strides=2)\n",
        "\n",
        "    conv4_1 = tf.layers.conv2d(\n",
        "        inputs=pool3,\n",
        "        filters=256,\n",
        "        kernel_size=[3, 3],\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu,\n",
        "        name=\"conv7\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "\n",
        "    conv4_1_n = tf.contrib.layers.batch_norm(conv4_1,\n",
        "                                        center=True,\n",
        "                                        scale=True, \n",
        "                                        is_training=training,\n",
        "                                            scope=\"convb7\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    conv4_2 = tf.layers.conv2d(\n",
        "        inputs=conv4_1_n,\n",
        "        filters=256,\n",
        "        kernel_size=[3, 3],\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu,\n",
        "        name=\"conv8\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "\n",
        "    conv4_2_n = tf.contrib.layers.batch_norm(conv4_2,\n",
        "                                        center=True,\n",
        "                                        scale=True, \n",
        "                                        is_training=training,\n",
        "                                            scope=\"convb8\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    pool4 = tf.layers.max_pooling2d(inputs=conv4_2_n, pool_size=[3, 3], strides=2)\n",
        "\n",
        "    # Dense layer\n",
        "\n",
        "    pool2_flat = tf.reshape(pool4, [-1, 7*7*256])\n",
        "    dense_l = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu, reuse=tf.AUTO_REUSE, name=\"dense1\")\n",
        "\n",
        "    if (features):\n",
        "      return dense_l\n",
        "    \n",
        "    # Logits Layer\n",
        "\n",
        "    logits = tf.layers.dense(inputs=dense_l, units=max_num_categories, reuse=tf.AUTO_REUSE, name=\"dense2\")\n",
        "  \n",
        "  return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vCs0P712RNJJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento de skNet"
      ]
    },
    {
      "metadata": {
        "id": "nJlFunVeHA3g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "668570ba-ea2a-43d0-8add-876ef243aa6d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532556340338,
          "user_tz": 240,
          "elapsed": 137767,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "snapshot_path = \"./training_sknet/training/snap-sknet.ckpt\"\n",
        "list_scopes = [\"conv[12345678]\", \"convb[12345678]\", \"dense[12]\"]\n",
        "loss_array, train_acc, test_acc = train_net(skNet, 200, 1, 0.01, snapshot_path, True, list_scopes, False, True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./training_sknet/training/snap-sknet.ckpt\n",
            "step 0, training set accuracy 0.875\n",
            "step 20, training set accuracy 0.89\n",
            "test set accuracy 0.741800000667572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-DZLfNAKtMQ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Descargar el modelo entrenado (opcional)"
      ]
    },
    {
      "metadata": {
        "id": "K3ZHu3WeIxtP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "962834f4-bab5-4c5a-fbbc-343afd803436",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528667700824,
          "user_tz": 240,
          "elapsed": 45763,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!tar czf training.tar.gz training/ \n",
        "files.download('training.tar.gz') "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  drive\ttest  test.tar.gz  train  training  train.tar.gz\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "noiUU9T9Wgkm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Construcción y entrenamiento de la skResNet"
      ]
    },
    {
      "metadata": {
        "id": "z9aoZp_rWlzg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Construcción del grafo"
      ]
    },
    {
      "metadata": {
        "id": "ST115cKqWiRw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def skResNet(x, training=False, features=False):\n",
        "  with tf.name_scope('reshape'):\n",
        "    x_image = tf.reshape(x, [-1, 128, 128, 1])       \n",
        "\n",
        "  conv1_1 = tf.layers.conv2d(\n",
        "    inputs=x_image,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "    name=\"conv1\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv1_1_n = tf.contrib.layers.batch_norm(conv1_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conb1\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  conv1_2 = tf.layers.conv2d(\n",
        "    inputs=conv1_1_n,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"conv2\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv1_2_n = tf.contrib.layers.batch_norm(conv1_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conb2\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "\n",
        "  pool1 = tf.layers.max_pooling2d(inputs=conv1_2_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  conv2_1 = tf.layers.conv2d(\n",
        "    inputs=pool1,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"conv3\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv2_1_n = tf.contrib.layers.batch_norm(conv2_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conb3\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  conv2_2 = tf.layers.conv2d(\n",
        "    inputs=conv2_1_n,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"conv4\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv2_2_n = tf.contrib.layers.batch_norm(conv2_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conb4\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  residual_1 = conv2_2_n + pool1\n",
        "  \n",
        "  conv3_1 = tf.layers.conv2d(\n",
        "    inputs=residual_1,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"conv5\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv3_1_n = tf.contrib.layers.batch_norm(conv3_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conb5\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  conv3_2 = tf.layers.conv2d(\n",
        "    inputs=conv3_1_n,\n",
        "    filters=64,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"conv6\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv3_2_n = tf.contrib.layers.batch_norm(conv3_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conb6\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  residual_2 = conv3_2_n + residual_1\n",
        "  \n",
        "  conv4_1 = tf.layers.conv2d(\n",
        "    inputs=residual_2,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"conv7\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv4_1_n = tf.contrib.layers.batch_norm(conv4_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conb7\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  pool2 = tf.layers.max_pooling2d(inputs=conv4_1_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  conv5_1 = tf.layers.conv2d(\n",
        "    inputs=pool2,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"conv8\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv5_1_n = tf.contrib.layers.batch_norm(conv5_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conb8\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  conv5_2 = tf.layers.conv2d(\n",
        "    inputs=conv5_1_n,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"conv9\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv5_2_n = tf.contrib.layers.batch_norm(conv5_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conb9\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  residual_3 = conv5_2_n + pool2\n",
        "  \n",
        "  conv6_1 = tf.layers.conv2d(\n",
        "    inputs=residual_3,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"conva\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv6_1_n = tf.contrib.layers.batch_norm(conv6_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conba\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  conv6_2 = tf.layers.conv2d(\n",
        "    inputs=conv6_1_n,\n",
        "    filters=128,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"convb\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv6_2_n = tf.contrib.layers.batch_norm(conv6_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conbb\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  residual_4 = conv6_2_n + residual_3\n",
        "  \n",
        "  conv7_1 = tf.layers.conv2d(\n",
        "    inputs=residual_4,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"convc\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv7_1_n = tf.contrib.layers.batch_norm(conv7_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conbc\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  pool3 = tf.layers.max_pooling2d(inputs=conv7_1_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  conv8_1 = tf.layers.conv2d(\n",
        "    inputs=pool3,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"convd\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv8_1_n = tf.contrib.layers.batch_norm(conv8_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conbd\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  conv8_2 = tf.layers.conv2d(\n",
        "    inputs=conv8_1_n,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"conve\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv8_2_n = tf.contrib.layers.batch_norm(conv8_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conbe\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  residual_5 = conv8_2_n + pool3\n",
        "  \n",
        "  conv9_1 = tf.layers.conv2d(\n",
        "    inputs=residual_5,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"convf\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv9_1_n = tf.contrib.layers.batch_norm(conv9_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conbf\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  conv9_2 = tf.layers.conv2d(\n",
        "    inputs=conv9_1_n,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"convg\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv9_2_n = tf.contrib.layers.batch_norm(conv9_2,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conbg\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  residual_6 = conv9_2_n + residual_5\n",
        "  \n",
        "  conv10_1 = tf.layers.conv2d(\n",
        "    inputs=residual_6,\n",
        "    filters=256,\n",
        "    kernel_size=[3, 3],\n",
        "    padding=\"same\",\n",
        "    activation=tf.nn.relu,\n",
        "      name=\"convh\",\n",
        "    reuse=tf.AUTO_REUSE,\n",
        "    trainable=True)\n",
        "  \n",
        "  conv10_1_n = tf.contrib.layers.batch_norm(conv10_1,\n",
        "                                    center=True,\n",
        "                                    scale=True, \n",
        "                                    is_training=training,\n",
        "                                            scope=\"conbh\",\n",
        "                                            reuse=tf.AUTO_REUSE)\n",
        "  \n",
        "  pool4 = tf.layers.max_pooling2d(inputs=conv10_1_n, pool_size=[3, 3], strides=2)\n",
        "  \n",
        "  # Dense layer\n",
        "  \n",
        "  pool2_flat = tf.reshape(pool4, [-1, 7*7*256])\n",
        "  dense_l = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu, reuse=tf.AUTO_REUSE, name=\"dense_res_1\")\n",
        "  \n",
        "  if (features):\n",
        "    return dense_l\n",
        "  \n",
        "  dense_dropout = tf.nn.dropout(dense_l, 0.65, name=\"dropout_res\")\n",
        "  \n",
        "  # Logits Layer\n",
        "  \n",
        "  logits = tf.layers.dense(inputs=dense_dropout, units=max_num_categories, reuse=tf.AUTO_REUSE, name=\"dense_res_2\")\n",
        "  \n",
        "  return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q89XfUjXcO1S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento de skResNet"
      ]
    },
    {
      "metadata": {
        "id": "qn00RoAVcL79",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a03a59fa-0e72-4790-bbfd-77816a0801a3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532556549300,
          "user_tz": 240,
          "elapsed": 158193,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "snapshot_path = \"./training/training/snap-skresnet.ckpt\"\n",
        "list_scopes = [\"conv[123456789abcdefgh]\", \"conb[123456789abcdefgh]\", \"dense_res_[12]\", \"dropout_res\"]\n",
        "loss_array_res, train_acc_res, test_acc_res = train_net(skResNet, 200, 6, 0.01, snapshot_path, True, list_scopes, False, True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./training/training/snap-skresnet.ckpt\n",
            "step 0, training set accuracy 0.91\n",
            "step 20, training set accuracy 0.93\n",
            "test set accuracy 0.7113999986648559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0IfipO4l3DVa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!zip -r training_res.zip training/ \n",
        "files.download('training_res.zip') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zwIAKsna0bNm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "22e0d24e-e76b-46c2-ded5-a02e52fd2769",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528821855826,
          "user_tz": 240,
          "elapsed": 16371,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!zip -r training.zip training/\n",
        "!cp training.zip drive/data_quickdraw/training.zip\n",
        "#!ls training"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: training/ (stored 0%)\r\n",
            "  adding: training/checkpoint (deflated 41%)\r\n",
            "  adding: training/snap-skresnet.ckpt.index (deflated 64%)\n",
            "  adding: training/snap-data (deflated 10%)\n",
            "  adding: training/snap-skresnet.ckpt.data-00000-of-00001 (deflated 10%)\n",
            "  adding: training/snap-skresnet.ckpt.meta (deflated 91%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lxwz1e9aGBer",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Búsqueda por similitud en skNet y skResNet"
      ]
    },
    {
      "metadata": {
        "id": "N58_H6RaHi5x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Se crea clase para obtener los vectores de características de cada imagen y guardarlas en un txt por clase."
      ]
    },
    {
      "metadata": {
        "id": "9ExZxOMx6prO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "085a8f0f-d215-4ad5-ff9b-ef80bedda26f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532556611929,
          "user_tz": 240,
          "elapsed": 4032,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "features_path = \"features/\"\n",
        "features_res_path = \"features_resnet/\"\n",
        "!mkdir features\n",
        "!mkdir features_resnet\n",
        "!ls"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘features’: File exists\n",
            "mkdir: cannot create directory ‘features_resnet’: File exists\n",
            "datalab   features_resnet  train\t   training_sknet.zip\n",
            "drive\t  test\t\t   training\t   training.zip\n",
            "features  test.tar.gz\t   training_sknet  train.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UwWJUGsC6-wy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for idx in range(max_num_categories):\n",
        "  os.system(\"mkdir \" + features_path + str(idx))\n",
        "  os.system(\"mkdir \" + features_res_path + str(idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kp1r0nPmGX5u",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class FeatureExtractor():\n",
        "  @staticmethod\n",
        "  def createTxtFeatures(dnn_graph, snapshot_path = \"./training_sknet/training/snap-sknet.ckpt\", layer_scopes = [\"conv[12345678]\", \"convb[12345678]\", \"dense[12]\"], features_path=features_path, feature_file=\"features\"):\n",
        "    data_path = \"test/\"   \n",
        "    \n",
        "    x = tf.placeholder(tf.float16, shape=(None, 128*128))      \n",
        "    features = dnn_graph(x, False, True)     \n",
        "    \n",
        "    with tf.Session() as sess:       \n",
        "      reuse_vars = []\n",
        "\n",
        "      for cusScope in layer_scopes:\n",
        "        reuse_vars += tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                     scope=cusScope)      \n",
        "\n",
        "      reuse_vars_dict = dict([(var.op.name, var) for var in reuse_vars])\n",
        "      saver = tf.train.Saver(reuse_vars_dict)\n",
        "      saver.restore(sess, snapshot_path)    \n",
        "    \n",
        "      for img_class in range(max_num_categories):\n",
        "        features_aux = []\n",
        "      \n",
        "        for img in range(test_samples_per_cat):\n",
        "          img_input = np.loadtxt(data_path + str(img_class) + \"/\" + str(img) + \".txt\")\n",
        "          img_input = np.resize(img_input, (1, 16384))          \n",
        "\n",
        "          features_aux.append(features.eval(feed_dict={x: img_input})[0])\n",
        "      \n",
        "        np.savetxt(features_path + str(img_class) + \"/\" + feature_file + \".txt\", features_aux, delimiter=' ')\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXGH6KGigkJo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Se extraen las caracteristicas con el modelo skNet"
      ]
    },
    {
      "metadata": {
        "id": "wk9pusbyLlvh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "706b5f7f-7ad7-48f4-f017-c5678b4e66f5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532556842828,
          "user_tz": 240,
          "elapsed": 105354,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "FeatureExtractor.createTxtFeatures(skNet)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./training_sknet/training/snap-sknet.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JD8_3K2WgqGK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Se extraen las caracteristicas con el modelo skResNet"
      ]
    },
    {
      "metadata": {
        "id": "FI31jfLANsd_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44d111c3-9b77-4c80-d982-f85da815ffd9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532557001706,
          "user_tz": 240,
          "elapsed": 137117,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "snapshot_path = \"./training/training/snap-skresnet.ckpt\"\n",
        "list_scopes = [\"conv[123456789abcdefgh]\", \"conb[123456789abcdefgh]\", \"dense_res_[12]\", \"dropout_res\"]\n",
        "FeatureExtractor.createTxtFeatures(skResNet, snapshot_path, list_scopes, \"features_resnet/\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./training/training/snap-skresnet.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q2J_ZEoX7zx9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# descargamos los features\n",
        "!zip -r features.zip features/\n",
        "!cp features.zip drive/data_quickdraw/features.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vr-n1hjoQoTC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# resnet\n",
        "!zip -r features_resnet.zip features_resnet/\n",
        "!cp features_resnet.zip drive/data_quickdraw/features_resnet.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YsmB-Dhk5Cfn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Se calculan los rankings según distancia L2 y luego se calculan los Average Precision junto con el mAP"
      ]
    },
    {
      "metadata": {
        "id": "3k6WcgCi5J_V",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class MeanAveragePrecision():\n",
        "  @staticmethod\n",
        "  def getMAP(features_path=features_path, feature_file=\"features\"):\n",
        "    listaPrecision = []\n",
        "    \n",
        "    for img_class in range(max_num_categories):\n",
        "      classFeatures = np.loadtxt(features_path + str(img_class) + \"/\" + feature_file + \".txt\")\n",
        "      distance_matrix = []\n",
        "      \n",
        "      for img_class_aux in range(max_num_categories):\n",
        "        classFeaturesAux = np.loadtxt(features_path + str(img_class_aux) + \"/\" + feature_file + \".txt\")\n",
        "        class_distances = []        \n",
        "        \n",
        "        for idj, feature in enumerate(classFeatures):\n",
        "          if (img_class == img_class_aux):   # leave-one-out\n",
        "            classFeaturesAux2 = np.delete(classFeaturesAux, [idj], 0)\n",
        "          else:\n",
        "            classFeaturesAux2 = classFeaturesAux\n",
        "          \n",
        "          differences = classFeaturesAux2 - feature\n",
        "\n",
        "          distances = np.sum(np.power(differences, 2), axis=1).reshape(1, len(differences))\n",
        "          \n",
        "          myFunc = lambda x: {'dist': x, 'class': img_class_aux}\n",
        "          vfunc = np.vectorize(myFunc)\n",
        "          distances_aux_classes = vfunc(distances)\n",
        "          \n",
        "          if (len(class_distances) == 0):\n",
        "            class_distances = distances_aux_classes\n",
        "          else:            \n",
        "            class_distances = np.concatenate((class_distances, distances_aux_classes), axis=0)             \n",
        "\n",
        "        if (len(distance_matrix) == 0):\n",
        "          distance_matrix = class_distances\n",
        "        else:\n",
        "          distance_matrix = np.concatenate((distance_matrix, class_distances), axis=1)          \n",
        "      \n",
        "      # el siguiente ciclo for obtiene el ranking\n",
        "      # y el for anidado calcula el Average Precision\n",
        "      for idx in range(test_samples_per_cat):\n",
        "        aux_row = distance_matrix[idx, :]\n",
        "        ranking = sorted(aux_row, key=lambda k: k['dist'])   # increasing order\n",
        "        accum_precision = 0\n",
        "        relevantes = 0\n",
        "        \n",
        "        for idz, objRanking in enumerate(ranking):\n",
        "          if (objRanking['class'] == img_class):\n",
        "            relevantes += 1\n",
        "            accum_precision += relevantes/(idz+1)\n",
        "        \n",
        "        listaPrecision.append(accum_precision*1.0/(test_samples_per_cat-1))\n",
        "      \n",
        "    return sum(listaPrecision)/len(listaPrecision)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xuTpJD87PKC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b84e8c41-4b10-4265-f219-83b16151226a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532488483798,
          "user_tz": 240,
          "elapsed": 1231405,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "map_value = MeanAveragePrecision.getMAP()\n",
        "print(map_value)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0214979591837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tPvp3PjjNT1Z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9aba7524-e270-4a59-a857-ad77b42c3e8d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532487221840,
          "user_tz": 240,
          "elapsed": 1152186,
          "user": {
            "displayName": "Martín Cornejo-Saavedra",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100137397923643336617"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "map_value = MeanAveragePrecision.getMAP(features_res_path)\n",
        "print(map_value)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.018906122449\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}